---
layout: slide
title: "DynamoDB"
description: ""
theme: black
transition: slide
categories: [presentation]
permalink: presentations/:title
published: true
---
<section data-markdown data-separator="^\n----\n" data-separator-vertical="^\n---\n">
<script type="text/template">
# DynamoDB

----

### Table of Contents:

- Introduction
- Choosing Right Indexes
- CRUD operations
- Querying
- Capacity Units
- Partitioning 1 - the beginning
- Partitioning 2 - the conclusion

----

### What is DynamoDB?

###### Fully managed NoSQL database service that provides fast and predictable performance with seamless scalability.

----

### Benefits

- Data is stored on solid state disks (SSDs)
- Automatically replicated across multiple Availability Zones in an AWS region
- Ability to handle large amount of data
- Integration with various AWS services such as EMR, Redshift, Cognito.
- High performance
- Scalability

----

### You don’t Need to:

- Worry about hardware provisioning
- Manage distributed database
- Setup and Configuration
- Replication
- Software Patching
- Cluster Scaling

----

### Indexes

- Primary Key - Uniquely Identifies each item
  - Simple Primary Key - Partition Key
  - Composite Primary Key - Partition Key + Sort Key

---

### Indexes

- Secondary Indexes
  - Global Secondary Indexes
  - Local Secondary Indexes - Has same Partition Key as base table
  - Every secondary index is automatically maintained by DynamoDB. When you add, modify, or delete items in the base table, any indexes on that table are also updated to reflect these changes.

---

### Indexes

- A secondary index is a data structure that contains a subset of attributes from a table, along with an alternate key to support Query operations. You can retrieve data from the index using a Query, in much the same way as you use Query with a table.

----

### Operations on Items

###### Basic CRUD:

- PutItem (create)
  - Can return ALL_OLD
- GetItem (read)
- UpdateItem (update)
  - More of an upsert (update if exists, create if does not exists)
  - Can return ALL_OLD, ALL_NEW, UPDATED_OLD, UPDATED_NEW
- DeleteItem (delete)
  - Can return ALL_OLD

---

### Operations on Items

##### Batch Operations(can be used to perform operations across tables):

- Batch operations does not fail unless all operations fail
- BatchGetItem - get upto 100 items (synonymous to stuffing 100 GetItem calls)
- BatchWriteItem  - create / delete upto 25 items

---

### Operations on Items

##### Conditional Writes


----

### Scan

---

- A Scan operation reads every item in a table or a secondary index.
- Use filters to narrow down results.
- It can return maximum  1MB of data. Use pagination to fetch further data.

---

##### Capacity units consumption:

- Table - it consumes read capacity from Table’s provisioned read capacity
- Local Secondary Index - index’s base table’s provisioned read capacity
- Global Secondary Index - index’s provisioned read capacity

---

##### Not good approach to query the data:

- Filters applied after scanning the data. Hence,
  - More capacity units consumption
  - Slower compared to Query operation

----

### Query

---

- To find Items based on Primary or Index Key attributes
- Use filters to get items specific to attributes other than Primary or Index key attributes
- Hash Key or Index Key must be some specific value, Range key can use other conditional operators.
- Max 1MB data can be retrieved, Use pagination to fetch further data.

----

### Capacity Units

---

#### Write Capacity Units (WCU) :

Total Write Capacity = (round(size of 1 item)) * (n writes / second) * (number of indexes)

---

#### Read Capacity Units (RCU):

- Eventual consistent Reads costs half compared to Strongly Consistent Reads
- 1 RCU = 1 Strongly Consistent Read / Second
- Total Read Capacity = round (size of item / 4kB) * (n read / second)

---

#### Example:

- Size of an item = 1 kB => 1/ 4 => round(0.25) => 1 unit for reading an item
- Now, if we want 100 reads / second => 1 * 100 => 100 strongly consistent read capacity units

---

#### When Query and Scan used, DynamoDB uses the cumulative size of the processed items to calculate provisioned throughput.

- 100 items are retrieved, with each item having size of 1 kB, consumed read capacity would be
  - (100 * 1024 bytes = 100 kB) / 4 kB = 25 read capacity units

----

### Partitioning - The beginning

- AWS handles partitioning for you automatically, creates new partitions and distributes provisioned throughput capacity evenly across them.
- We recommend that you choose a partition key that can have a large number of distinct values relative to the number of items in the table.
- Clever Worker (Partitioning based on Hashing Algorithm) under Dumb Manager (All capacity units are spread equally among all partitions)
- One partition can hold multiple partition keys, and one partition key can belong to only one partition.

----

### Partitioning - The conclusion

- Performance Aspect: ( RCU / 3,000 ) + ( WCU / 1,000 ) = initialPartitions (rounded up)
  - Eg., 1500 / 3000 + 500 / 1000 => 0.5 + 0.5 => round(1) => 1 partition is enough
- Storage Aspect: 1 partition can hold max 10 GB of data

---

##### When partitions take place?

- Crossed 10 GB limit, or
- When specified RCU exceeds 3000 units or WCU exceeds 1000 units for a partition   
- In such case, 2 equal partitions are created
  - Each partition will get 1500 / 2 => 750 RCU, 500 / 2 => 250 WCU
- Total partitions =MAX(Total partitions for desired performance,Total partitions for desired capacity)

---

### Conclusions / TL;DR / Advice / Whatever:

- Choose Primary Key and Indexes according to usage pattern of your application.
- A good partition key is unique. (ideal world)
- A good partition key has as many distinct values as possible.
- A good partition key evenly spreads data.

----

# Gracias!
###### Meet me at my website: <a href="http://parthrmodi.com">parthrmodi.com</a> or follow my articles at: <a href="http://parthrmodi.com/blog">parthrmodi.com/blog</a>

</script>
</section>
